# ğŸ“„ PDF Q&A Assistant

An intelligent document assistant that lets you upload any PDF and ask context-based questions. It uses local embeddings with FAISS and a Groq-powered LLM (e.g., LLaMA 3) to return accurate answers from your document â€” and only from your document.

> âš ï¸ If the answer is not present in the PDF, the assistant will respond:
> _"The answer is not in the document."_

---

## ğŸ”§ Features

- âœ… Upload any PDF document
- ğŸ§  Automatically chunk and embed the text using `HuggingFaceEmbeddings`
- ğŸ“š Store embeddings locally using `FAISS`
- ğŸ’¬ Query with a custom prompt using LLaMA (via Groq API)
- ğŸ” Return answers strictly based on the uploaded PDF content
- ğŸ“Œ Source chunks shown for each answer

---

# How It Works
**Ingestion (ingest.py)**

Loads PDF using PyPDFLoader

Splits into overlapping chunks with RecursiveCharacterTextSplitter

Embeds the chunks using HuggingFaceEmbeddings

Saves the vector store locally with FAISS

**Q&A Chain (qa_chain.py)**

Loads vector store and retrieves relevant chunks

Queries the LLaMA model (via Groq API) with a strict context-based prompt

**Streamlit App (app.py)**

Handles file upload, vector store creation, and interactive Q&A


# Example Use Cases
GATE/UPSC/Exam syllabus PDFs

Legal or policy documents

Research papers

Technical documentation




